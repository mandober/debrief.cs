# Hardware vs Software

Hardware and software is like mind and body. 
Hardware is the necessary physical substrate 
but it cannot do anything on its own, without the software. 
Software is the "spirit movens" 
that lives in the machine (ghost in the machine), 
but it cannot do anything on its own, without the hardware. 
Both hardware and software are needed; 
they cannot function one without the other. 

In the beginning of the computer age, the first computers produced were enormous (by todays standards). They would occupy entire rooms or even floors. They were quite imposing, leaving no room to think about software. Perhaps that was because software (as we know it today) didn't really exist then. Those early computers were "programmed" using patch cables, thus software, data or code, weren't yet a thing. Perhaps some notion of code existed but it has buried on all that hardware and not at the forefront.

In time, patch cables evolved into punctured cardboards, which were many steps closer to the notion of software and code. This was a time when software had a weak physical form, and had to be proected from environmetal threats like humidity, water, fire. Today, a strage medium is securely erased by filling it with zeros; magnetic storage is particularly stubborn and must be erased in many steps. The method of secure erasure in those days was by fire. Also, bugs were physical, not abstract. Real moths would nest in the parts of those big-ass computers.

The cost of all that hardware was obviously astronomical. That trend continued for years, no one really begun to consider software. Programming was done standing-up, as a challenge to get the machine to do the right thing. Software hasn't even started to settle into some stable form, anything was possible.

IBM was the world's primary supplier of computers. For years, everyone was equating computers to hardware, especially at IBM. After all, hardware was very real and carried an astronomical cost still, while software was barely defined, if at all. No wonder everyone only thought about hardware. This continued even as software shifted its shape again and started to inhabit various storage devices and early drivers. IBM, as the leader in computer manifacture, deemed hardware the king, and never even considered the possibility that things could be otherwise. Hardware was very expensive, and software wasn't even properly defined. Plus you couldn't put a price on something so abstract; on the other hand, everyone who witnessed one of those furniture-sized computers knew where the money went.

In time, software got to be recognized for its role in computing. Hardware was still the king, cost-wise. But the bird's eye view showed that the cost of hardware was slowely decreasing, and the cost of software was slowely increasing.

>The 1970's mark the decade when the cost of software overtook the cost of hardware.

After that, the hardware was imitating software but in reverse. After the spread of personal computers and the Internet, hardware become (extremely, in comparision) cheap. The people started to realize how valuable and irreplacable their data is.

Software became king.
