# Locality of referencehttps://en.wikipedia.org/wiki/Locality_of_reference**Locality of reference** (principle of locality) is the observed tendency related to data access (e.g. accessing data in memory): repetitive access to data, across a small time frame, reveals the pattern that the accessed data tend to be very close together in term of space. In other words, dot-plotted graph of repetitive data access during a short period of time shows clustering (plotted dots tend to form clusters); the clustering indicates that the accessed data lives very close together.The two basic types of locality of reference are temporal and spatial locality.*Temporal locality* is the time aspect of locality of reference: during a short time span the data that is accessed tends to be in spatial proximity, implting that closely laid out data gets re-read and reused, within a small time frame. *Spatial locality* (data locality) refers to the use of data elements within relatively close storage locations. *Sequential locality*, a special case of spatial locality, occurs when data elements are arranged and accessed linearly, such as, traversing the elements in an array.These two properties describe the tendencies of general patterns of data access, they don't imply that all data exhibits them, so it maybe better stated that: a sequence of data accesses has **temporal locality** if accesses to a set of neighbouring values are clustered in time. A sequence of references (e.g. to values in memory) has **spatial locality** if the values referenced closely in time are also close together in space (e.g. neighbouring memory addresses). These properties have heavily influenced the design of CPUs, especially the desing of caches and caching logic. Therefore, if a data structure exhibits temporal and spacial locality, then the computations involving such data structures should have excellent performance.Locality is a type of predictable behavior that occurs in computer systems.Systems that exhibit strong locality of reference are great candidates for performance optimization through the use of techniques such as the caching, prefetching for memory and advanced branch predictors at the pipelining stage of a processor core.