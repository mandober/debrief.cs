# Functional Languages

(The Anatomy Of Programming Languages. Alice E. Fischer, Frances S. Grodzinsky. Prentice Hall. 1993. Chapter 12: Functional Languages)

## Overview

Functional languages have developed as semantically clean ways to denote objects, functions and function application. They have introduced the concept of denotation, that opposed computation. Functional constructs denote objects, in contrast to procedural constructs which specify methods for constructing objects.

Development of functional languages may be linked to lambda calculus, extended to denote types, literals, and operations for primitive data domains. Lazy evaluation and the absence of destructive assignment were also carried over.

Functional languages have a minimum of explicit control structures. Explicit loops are replaced by recursion. Sequences of statements can be replaced by lazy evaluation, nested context blocks, or nested procedure calls because there is no destructive assignment.

## Denotation versus Computation

During the 1960s, several researchers began work on proving things about programs. Efforts were made to establish the mathematical correctness of programs. The explorations also included coming up with the means to prove genral program corectnes, and it also included extensional vs intensional function equality.

Several difficult problems emerged from this work. One was the problem of specification: before one can prove that a program is correct, one must specify the meaning of the correct program, formally and unambiguously. Formal systems for specifying the meaning of a program were developed, and they looked suspiciously similar to programming languages. 

Researchers began to analyze why is it so harder to prove things about programs written in traditional languages than it is to prove theorems about mathematics. Two aspects of traditional languages emerged as sources of troubles, not just because they were difficult to model in a mathematical framework: mutability and sequencing of operations.

### Mutability

Mathematics is a pure denotational system. A symbol, once defined in a given context, means one and the same thing. The truth or falsity of a mathematical statement is a permanent property of that statement; it does not change over time. One can say that math is immutable, that is, math variables are immutable.

On the other hand, programming languages have variables whose contents can be changed, not only at any time, but by any part of the program, even at the same time that another program's part is accessing or mutating the contents of that same variable. Thus a mathematical proof about a program that allows mutability is necessarily nonmodular and must consider all parts of the program at once.

### Sequencing

When a mathematician develops a theorem, he defines symbols, then writes down facts that relate those symbols. The order of those facts is unimportant, so long as all the symbols used are defined, and it certainly does not matter where each fact is written on the paper. A proof is a static thing - its parts just are, they do not act. In contrast, a program is a description of a dynamic process. It prescribes a sequence of actions to be taken, not a collection of facts. Sometimes the order of a pair of program statements does not matter, but other times it does. Some statements are in the scope of a loop and are evaluated many times, each time producing a different result. To fully describe a program during execution (which we call a process), we need not only the program code, but a copy of the stack, the values of global and static variables, the current values of the computer's program counter and other hardware registers, and a copy of the input.

### Denotation

Functional languages are an attempt to move away from all this complexity and toward a more mathematical way of specifying computation. In a functional language, each expression of the language denotes an object. Objects are pure values and may be primitive data elements such as integers, functions, or higher-order functions. Thus each expression can be thought of as a description of a static, mathematical entity rather than of a dynamic computation.

Some examples will help make this clear. The expression 3 denotes the integer 3, as do the expressions 2 + 1 and 5 − 2. The meanings of these expressions are fixed for all time and do not change depending on what has happened elsewhere in the program. In functional languages, these same properties are extended to functions (a function is a set of ordered pairs). The factorial function, n!, takes an integer argument n and returns a number n!, which is the product of the first n natural numbers. This mathematical function might be described in a functional way by a pair of recurrence equations, for example,

        fact 0 = 1
        fact n = n ∗ fact (n − 1) if n ≥ 1

The first equation describes the value of fact for argument 0. The second equation describes how the value of fact n is related to the value of fact(n − 1). It take some effort to show that there is a unique function (on the natural numbers) that satisfies these equations and hence that the equations do in fact specify a function, but it is clear from the form of the equations that whatever the meaning is, it does not depend on the history of execution up to this point. We say that this pair of equations denote the mathematical function n!.

Denotational semantics is a way of describing the meaning of a programming language construct by giving the mathematical object that it denotes. In the above examples, the meaning of 2+1 is the integer 3, and the meaning of the two equations specifying fact is the factorial function.

Contrast this style of description with the C program for computing factorial. What this C expression denotes is the process of successively multiplying temporary variable by the integers 1,2,3,...n. In this case, the result of that process happens to be functional, and the program does indeed compute the factorial function, but it is not obvious without careful inspection of the code that the program in fact computes a function.

Functions are denoted by λ-expressions. For example, consider the function G denoted by the expression

        Let G be λf. λx. (if x = 0 then 1 else x * f(x − 1))

G denotes a function of two arguments, f, a function, and x, an integer. Suppose p is the function p(n) = 3n. Then Gp5 denotes the value of the expression if 5 = 0 then 1 else 5 ∗ p(5 − 1) which is equal to 5 ∗ p(4) = 5 ∗ 12 = 60.

**Fixed Points**. The function G above has a curious property: namely, if h is the mathematical function factorial(n), then G(h) is also the factorial function. We say that the factorial function is a fixed point of G because h = G(h). Moreover, it is the least fixed point in the sense that any function h0 satisfying the equation h0 = G(h0) agrees with factorial at all of the points where factorial is defined (the nonnegative integers). We can use this fact and the \least fixed point operator", Y , to write an expression that denotes the factorial function, namely Y G, or equivalently, Y λf:λx:( if x = 0 then 1 else x ∗ f(x − 1)) Intuitively, Y λf just means, \in the following expression, f refers recursively to the function being defined". 

A curiousity of lambda calculus is that Y itself can be denoted by a (rather complicated) lambda expression. Hence Y does not have to be added to the language as a special primitive for defining recursive functions. In practice, it almost always is added for efficiency reasons. Rather than replace Y by the equivalent lambda expression, it is much more efficient in the implementation to allow pointers to functions; then Y λf... simply binds f to the function being defined by the λx... expression. Lambda calculus is a sufficient semantic basis for expressing all computations because it is able to express the Y operator as a formula.

The fact that pure lambda calculus lacks types is not an oversight; it is necessary in order to define Y . The reason is that Y works with any function as its first argument, not just with functions of a specific type. Imposing a type structure on lambda calculus, as many functional languages do, weakens the lambda calculus and makes it necessary to introduce additional constructs to allow for recursive definitions. Convenience of use also dictates the addition of other constructs. Still, it is elegant that so simple a system as the untyped lambda calculus could be the basis of a powerful programming language!

## The Functional Approach

Abstractly a functional language is simply a system of notation for denoting primitive values and functions.

Lambda calculus, which was already proven to be a fully general formal system in which any computable function could be defined, was used as a notation for early functional languages.

However, lambda calculus has two serious shortcomings as a language for programmers: it lacks any concept of types and it is hopelessly clumsy to use.Nevertheless, lambda calculus has been taken as the starting point for the development of most real functional languages. The earliest practical language in this family was LISP, which now has two important descendants, Common LISP and Scheme.

Another class of languages has been developed recently, which we will call pure functional languages. These languages follow lambda calculus and functional principles much more closely. This family includes ML, Miranda, and Haskell.

An extended version of lambda calculus was developed which includes types and operators and literals for the underlying data domains. This system forms the semantic basis upon which the pure functional languages are built. Functional programs are parsed and translated into computation trees which represent lambda applications. At execution time, the lambda evaluator crawls over these trees, binding arguments, evaluating expressions as needed, and replacing expression trees by constant values wherever possible.

Pure functional languages come extremely close to implementing the semantics that Church defined for lambda calculus. They share many traits with the older functional languages, specificly, functions are first-class objects, conditional expressions are used, rather than conditional statements, and repetition is done implicitly or with recursion, not by explicit loops.

The key differences between the newer and the older functional languages are:
- The prohibition on destructive assignment
- The complete absence of statement sequences
- The use of lazy parameter evaluation

We will consider each of these issues and show how denotational constructs can take the place of procedural language elements.

### Eliminating Assignment

Destructive assignment causes semantic problems because it creates a time- and sequence-dependent change in the meaning of a name. Prohibiting destructive assignment does not imply that a programmer cannot give a name to a value, merely that a name, once bound to a value, must remain bound to the same value throughout the scope of the name. Thus the meaning of a name is constant, and not dependent on the order of execution. This greatly simplifies the task of understanding the program and proving that it is correct.

In procedural languages, assignment is used for several purposes:
1. To store the result of computing a subexpression.
2. In conjunction with conditional statements.
3. With a loop variable, to mark the progress of a loop.
4. To build complex data structures.

To show that assignment can be eliminated, we must show how each of these things can be accomplished, with reasonable efficiency and style, in a functional way. Programmers store the results of subexpressions goal (1) for many good reasons. When an expression is complex, a local name can be used to \break out" and name a portion of it, so that the structure and meaning of the entire expression can be made clearer. Local names are also used in Pascal for efficiency; rather than write a common subexpression several times, the subexpression is evaluated first, and its result is assigned to a local variable. The local name is then used in further computations. Both uses of local variables can reduce the complexity of expressions and make a Pascal program easier to understand and debug. It is easy to devise a functional method to meet this need. We simply need to let the programmer open a local context block in which to define local names for expressions.

Miranda provides three ways to define a symbol:
-- As a global symbol, by declaring the name with an \=", just as symbols are defined in lambda calculus.
- As a parameter name. The name is bound to an argument expression during a function call.
- As a local symbol, by using a where clause.

A Miranda where clause defines one or more local names and gives an expression for the meaning of each. The entire group of definitions forms a local context and can be implemented by a stack frame. Where clauses can also be nested, producing block structured name-binding.

Goal (2) is satisfied by using a conditional expression, which returns a value, instead of a conditional statement. The value returned by the conditional expression can be bound to a name by parameter binding or by a where clause.Extensive support for list data structures, including list constructors, whole-list operations with implied iteration, and expressions that denote complex lists all combine to minimize the need for loops, goal (3). Sequences of data values are represented as lists, and operations that process such
sequences are written by mapping simple operations over lists. This device eliminates the need for most explicit loops and many statement sequences. The remaining repetitive processes are programmed using recursion. These topics are discussed at length in Sections 12.2.2 and 12.3. Goal (4) is the only real difficulty. Prohibiting destructive assignment means that a data structure cannot be modified after it is created. For small data structures this is no problem, as a new copy of the structure can be created that incorporates any desired change. This, in fact, is how call-by-value works: objects are copied during the function call, and the new copies are bound to the parameter names within the function. Most list processing and a lot of processing on records and arrays can be done efficiently this way. The exception is when a large data structure, such as a 1000 element array, is used as a parameter and slightly modified within the subroutine. Copying it all in order to modify one element might produce unacceptable inefficiency.

Efficient implementation of arrays in a functional language is a current research topic. Work centers on the question of whether the original and modified versions of the array are both used. If not, then the language system can perhaps avoid the copy operation. It can do a destructive assignment to an array element \on the sly" and pretend that it didn’t. This trick will succeed if the program never again asks to see the original version of the array. 

Because of the efficiency problem with large arrays, existing pure functional languages are all list-oriented. When (and if) ways are found to circumvent these problems, careful design efforts will be needed to integrate arrays into functional languages. APL is an array-processing language that has many things in common with functional languages and lets the programmer use a functional programming style to do complex combinations of whole-array operations. To support this style, APL has a large and complex set of array operations [Exhibit 12.2]. The set of primitive composition and decomposition operations needed to make arrays usable without constant use of assignment is large compared to the set provided for list handling in Miranda. Today’s list-oriented functional languages are small and simple; tomorrow’s languages, with arrays added, will be larger and more complex.

### Recursion Replaces Loops


### Sequences


## Miranda
