# Parsing

https://en.wikipedia.org/wiki/Parsing

*Parsing* or *syntax analysis* is the process of analyzing a string of symbols, assumed to conform to the rules of a formal grammar, in terms of grammatical categories, identifying the parts and their syntactic functions and relations.

In CS, parsing results in a *parse tree* that shows the syntactic relation of grammatical categories to each other, possibly also containing semantic information. Some parsing algorithms generate a *parse forest* or *list of parse trees* if the input string is syntactically ambiguous.

The term "parsing" comes from Latin `pars`, "part".

## Parsers of computer languages

A parser is a software component that takes input data - typically source code of a programming language - and builds a data structure, which is often a kind of an abstract syntax tree (AST) or similar hierarchical structure that shows the structural representation of input, after checking for correctness of syntax.

The parser may be preceded by a separate *lexical analyser* (scanner), which creates *tokens* from the input characters; alternatively, these two phases may be combined in the so-called *scannerless parsing*. 

Parsers are rarely written by hand, usually being (semi-)automatically generated by *parser generators*.

An important class of simple parsing is done using regular expressions, in which a group of regular expressions defines a regular language. In other contexts, regular expressions may be used prior to parsing, as the lexing step whose output is then used by the parser. In general, however, using regular expressions to parse complex code is inferior and error prone to parsing, as stipulated by the "Parse, don't validate!" maxima.

The use of parsers varies by input. In the case of data (markup) languages, a parser is often a part of the program (parsing HTML is the job of a browser).

In the case of programming languages, a parser is a component of a compiler or interpreter and it parses the source code of a programming language to create some form of *internal representation*, usually as some kind of AST. Parser is a key step of a compiler frontend. Programming languages tend to be specified in terms of a *deterministic context-free grammar* (dCFG) because fast and efficient parsers can be written for them.

Depending on a language and needs, the compiler may run the parser in one pass or multiple passes. The implied disadvantages of a one-pass compiler can largely be overcome by adding *fix-ups*, where provision is made for *code relocation* during the forward pass, and the fix-ups are applied backwards when the current program segment has been recognized as having been completed. An example where such a fix-up mechanism would be useful would be a forward GOTO statement, where the target of the GOTO is unknown until the program segment is completed. In this case, the application of the fix-up would be delayed until the target of the GOTO was recognized. Conversely, a backward GOTO does not require a fix-up, as the location will already be known.

*Context-free grammars* (CFGs) are limited in the extent to which they can express all of the requirements of a language. Informally, the reason is that the memory of such a language is limited. The grammar cannot remember the presence of a construct over an arbitrarily long input; this is necessary for a language in which, for example, a name must be declared before it may be referenced, which some languages solve by introducing *forward declarations*.

More powerful grammars that can express this constraint, however, cannot be parsed efficiently. Thus, it is a common strategy to create a *relaxed parser* for a CFG which accepts a superset of the desired language constructs (that is, it accepts some invalid constructs); later, the unwanted constructs can be filtered out during *semantic analysis* (aka contextual analysis).
