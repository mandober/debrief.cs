# Information theory

https://en.wikipedia.org/wiki/Information_theory

Information theory
- Entropy
  - Differential entropy
  - Conditional entropy
  - Joint entropy
  - Relative entropy
  - Entropy rate
- Mutual information
  - Conditional mutual information
- Limiting density of discrete points
- Asymptotic equipartition property
- Rate-distortion theory
- Shannon's source coding theorem
- Channel capacity
- Noisy-channel coding theorem
- Shannon-Hartley theorem

*Information theory* is the scientific study of quantification, storage and communication of digital information.

The field was fundamentally established by the works of Harry Nyquist and Ralph Hartley, in the 1920s, and Claude Shannon in the 1940s.

The field is at the intersection of probability theory, statistics, computer science, statistical mechanics, information engineering and electrical engineering.

A key measure in information theory is entropy. *Entropy* quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process. For example, identifying the outcome of a coin flip provides less information (lower entropy) than specifying the outcome of a die roll. 

Some other important measures in information theory are mutual information, channel capacity, error exponents, and relative entropy.

Important sub-fields of information theory include source coding, algorithmic complexity theory, algorithmic information theory and information-theoretic security.

Applications of fundamental topics of information theory include
- lossless data compression (zip)
- lossy data compression (mp3, jpeg)
- channel coding (DSL)

Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones and the development of the Internet. The theory has also found applications in other areas, including statistical inference, cryptography, neurobiology, perception, linguistics, the evolution and function of molecular codes (bioinformatics), thermal physics, molecular dynamics, quantum computing, black holes, information retrieval, intelligence gathering, plagiarism detection, pattern recognition, anomaly detection, even art creation.
